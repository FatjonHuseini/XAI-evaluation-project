{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IntegratedGradientReplace.ipynb","provenance":[{"file_id":"1Zn2zz3Qiek-FpBB1UqWCPQJhTmYW0A7v","timestamp":1654766641630},{"file_id":"1I6YIHx0gWp3nAFkiLOrcOrggElaLmo-t","timestamp":1654293671391}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP+1HUmCeQijq+/k9yWar7g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"21e3c69ee55e4f54aa88b11e35afb79c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07ee2252513043ee9677c90960f9591e","IPY_MODEL_0dcdf056f6a1487685a5e126acae0d5f","IPY_MODEL_c1d71f70ac67473b9468ac734b961a2e"],"layout":"IPY_MODEL_35be5dcc929942e3ab2dc29d77b16095"}},"07ee2252513043ee9677c90960f9591e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ca2a6daac284608a51e96b224a45e01","placeholder":"​","style":"IPY_MODEL_9b3e8435d7674778962584e8eb2aa35f","value":"Downloading: 100%"}},"0dcdf056f6a1487685a5e126acae0d5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc82a81642a9436c812246c374cd6616","max":438196200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7542dfddf0a74862824f76e100cae650","value":438196200}},"c1d71f70ac67473b9468ac734b961a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db444be294f4255a1e3281fd8abdd13","placeholder":"​","style":"IPY_MODEL_e538b15a54544a6ab7f4f961cbc4d5cd","value":" 418M/418M [00:26&lt;00:00, 19.1MB/s]"}},"35be5dcc929942e3ab2dc29d77b16095":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ca2a6daac284608a51e96b224a45e01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b3e8435d7674778962584e8eb2aa35f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc82a81642a9436c812246c374cd6616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7542dfddf0a74862824f76e100cae650":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7db444be294f4255a1e3281fd8abdd13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e538b15a54544a6ab7f4f961cbc4d5cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XLlsorFB77hj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654698437527,"user_tz":-120,"elapsed":17047,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"043ddff6-f500-4cc8-a035-db3a59f94881"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting alibi[tensorflow]\n","  Downloading alibi-0.7.0-py3-none-any.whl (445 kB)\n","\u001b[K     |████████████████████████████████| 445 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (1.21.6)\n","Requirement already satisfied: scikit-learn<2.0.0,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (1.0.2)\n","Collecting transformers<5.0.0,>=4.7.0\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 79.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (4.64.0)\n","Requirement already satisfied: pandas<2.0.0,>=0.23.3 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (1.3.5)\n","Requirement already satisfied: scikit-image!=0.17.1,<0.20,>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (0.18.3)\n","Requirement already satisfied: dill<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (0.3.5.1)\n","Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (2.2.4)\n","Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (2.23.0)\n","Requirement already satisfied: scipy<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (1.4.1)\n","Requirement already satisfied: attrs<22.0.0,>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (21.4.0)\n","Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (3.2.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (4.2.0)\n","Requirement already satisfied: Pillow<10.0,>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (7.1.2)\n","Requirement already satisfied: tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi[tensorflow]) (2.8.2+zzzcolab20220527125636)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=0.23.3->alibi[tensorflow]) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.0.0->alibi[tensorflow]) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi[tensorflow]) (2.10)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[tensorflow]) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[tensorflow]) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[tensorflow]) (2021.11.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi[tensorflow]) (2.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2.0.0,>=0.22.0->alibi[tensorflow]) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2.0.0,>=0.22.0->alibi[tensorflow]) (1.1.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.4.1)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (7.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (2.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (57.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (1.0.7)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (0.9.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.0.6)\n","Collecting spacy-lookups-data<0.2.0,>=0.0.5\n","  Downloading spacy_lookups_data-0.1.0.tar.gz (28.0 MB)\n","\u001b[K     |████████████████████████████████| 28.0 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy[lookups]<4.0.0,>=2.0.0->alibi[tensorflow]) (3.8.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.14.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (2.8.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.26.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.1.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (2.8.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (14.0.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (3.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.5.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.46.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (2.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (3.17.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (3.3.7)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.8.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.10.0,>=2.0.0->alibi[tensorflow]) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (3.7.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 42.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.7.0->alibi[tensorflow]) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 84.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: spacy-lookups-data\n","  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for spacy-lookups-data: filename=spacy_lookups_data-0.1.0-py2.py3-none-any.whl size=28052158 sha256=d834403ce5fbd634b0c7632c109ee186705b9b94e0a3d608f4dff9b84782b883\n","  Stored in directory: /root/.cache/pip/wheels/b6/09/83/36dd0224ce32dcdf5e218b36362235ca2e50cece60a966ae1b\n","Successfully built spacy-lookups-data\n","Installing collected packages: pyyaml, tokenizers, spacy-lookups-data, huggingface-hub, transformers, alibi\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed alibi-0.7.0 huggingface-hub-0.7.0 pyyaml-6.0 spacy-lookups-data-0.1.0 tokenizers-0.12.1 transformers-4.19.2\n"]}],"source":["pip install alibi[tensorflow]"]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"id":"JxH5R1tG9GMF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654698440159,"user_tz":-120,"elapsed":2653,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"066572a3-85b6-4a70-d85b-39495ac95bdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n"]}]},{"cell_type":"code","source":["import re\n","import os\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.cm\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","from tqdm import tqdm\n","from typing import Optional, Union, List, Dict\n","from IPython.display import HTML\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from transformers import PreTrainedTokenizer\n","from alibi.explainers import IntegratedGradients"],"metadata":{"id":"UgkROez89JdF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decode_sentence(x: List[int], reverse_index: Dict[int, str], unk_token: str = '[UNK]') -> str:\n","    \"\"\" \n","    Decodes the tokenized sentences from keras IMDB dataset into plain text.\n","    \n","    Parameters\n","    ----------\n","    x\n","        List of integers to be docoded.\n","    revese_index:\n","        Reverse index map, from `int` to `str`.\n","    unk_token:\n","        Unkown token to be used.\n","        \n","    Returns\n","    -------\n","        Decoded sentence.\n","    \"\"\"\n","    # the `-3` offset is due to the special tokens used by keras\n","    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n","    return \" \".join([reverse_index.get(i - 3, unk_token) for i in x])\n","\n","\n","def process_sentences(sentence: List[str], \n","                      tokenizer: PreTrainedTokenizer, \n","                      max_len: int) -> Dict[str, np.ndarray]:\n","    \"\"\"\n","    Tokenize the text sentences.\n","    \n","    Parameters\n","    ----------\n","    sentence:\n","        Sentence to be processed.\n","    tokenizer:\n","        Tokenizer to be used.\n","    \n","    Returns\n","    -------\n","        Tokenized representation containing:\n","         - input_ids\n","         - attention_mask\n","    \"\"\"\n","    # since we are using the model for classification, we need to include special char (i.e, '[CLS]', ''[SEP]')\n","    # check the example here: https://huggingface.co/transformers/v4.4.2/quicktour.html\n","    z = tokenizer(sentence, \n","                  add_special_tokens=True, \n","                  padding='max_length', \n","                  max_length=max_len, \n","                  truncation=True,\n","                  return_attention_mask = True,  \n","                  return_tensors='np')\n","    return z"],"metadata":{"id":"XEiQGez59Qrf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def  hlstr(string: str , color: str = 'white') -> str:\n","    \"\"\"\n","    Return HTML markup highlighting text with the desired color.\n","    \"\"\"\n","    return f\"<mark style=background-color:{color}>{string} </mark>\"\n","\n","\n","def colorize(attrs: np.ndarray, cmap: str = 'PiYG') -> List:\n","    \"\"\"\n","    Compute hex colors based on the attributions for a single instance.\n","    Uses a diverging colorscale by default and normalizes and scales\n","    the colormap so that colors are consistent with the attributions.\n","    \n","    Parameters\n","    ----------\n","    attrs:\n","        Attributions to be visualized.\n","    cmap:\n","        Matplotlib cmap type.\n","    \"\"\"\n","    cmap_bound = np.abs(attrs).max()\n","    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n","    cmap = mpl.cm.get_cmap(cmap)\n","    return list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n","\n","\n","def display(X: np.ndarray, \n","            attrs: np.ndarray, \n","            tokenizer: PreTrainedTokenizer,\n","            pred: np.ndarray) -> None:\n","    \"\"\"\n","    Display the attribution of a given instance.\n","    \n","    Parameters\n","    ----------\n","    X:\n","        Instance to display the attributions for.\n","    attrs:\n","        Attributions values for the given instance.\n","    tokenizer:\n","        Tokenizer to be used for decoding.\n","    pred:\n","        Classification label (prediction) for the given instance.\n","    \"\"\"\n","    pred_dict = {1: 'Positive review', 0: 'Negative review'}\n","    \n","    # remove padding\n","    fst_pad_indices = np.where(X ==tokenizer.pad_token_id)[0]\n","    if len(fst_pad_indices) > 0:\n","        X, attrs = X[:fst_pad_indices[0]], attrs[:fst_pad_indices[0]]\n","    \n","    # decode tokens and get colors\n","    tokens = [tokenizer.decode([X[i]]) for i in range(len(X))]\n","    colors = colorize(attrs)\n","    \n","    print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))\n","    return HTML(\"\".join(list(map(hlstr, tokens, colors))))"],"metadata":{"id":"dgLOPtzg9U9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n","\n","# load model and tokenizer\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n","\n","model = TFAutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["21e3c69ee55e4f54aa88b11e35afb79c","07ee2252513043ee9677c90960f9591e","0dcdf056f6a1487685a5e126acae0d5f","c1d71f70ac67473b9468ac734b961a2e","35be5dcc929942e3ab2dc29d77b16095","5ca2a6daac284608a51e96b224a45e01","9b3e8435d7674778962584e8eb2aa35f","bc82a81642a9436c812246c374cd6616","7542dfddf0a74862824f76e100cae650","7db444be294f4255a1e3281fd8abdd13","e538b15a54544a6ab7f4f961cbc4d5cd"]},"id":"f5lM7qCw9Ze1","executionInfo":{"status":"ok","timestamp":1654698525510,"user_tz":-120,"elapsed":46301,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"94b6aef6-7d21-48c7-ac22-ea8cfc4fdabc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e3c69ee55e4f54aa88b11e35afb79c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkWuO3qitpVI","executionInfo":{"status":"ok","timestamp":1654698566121,"user_tz":-120,"elapsed":555,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"ca7144ca-6012-4721-95a0-69d1df3ab2e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification object at 0x7fd184f0cf90>\n"]}]},{"cell_type":"code","source":["# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","# # load model and tokenizer\n","# model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"],"metadata":{"id":"5pntCdPM-uI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AutoModelWrapper(keras.Model):\n","    def __init__(self, transformer: keras.Model, **kwargs):\n","        \"\"\"\n","        Constructor.\n","        \n","        Parameters\n","        ----------\n","        transformer:\n","            Transformer to be wrapped.\n","        \"\"\"\n","        super().__init__()\n","        self.transformer = transformer\n","\n","    def call(self, \n","             input_ids: Union[np.ndarray, tf.Tensor], \n","             attention_mask: Optional[Union[np.ndarray, tf.Tensor]] = None,\n","             training: bool = False):\n","        \"\"\"\n","        Performs forward pass throguh the model.\n","        \n","        Parameters\n","        ----------\n","        input_ids:\n","            Indices of input sequence tokens in the vocabulary.\n","        attention_mask:\n","            Mask to avoid performing attention on padding token indices.\n","        \n","        Returns\n","        -------\n","            Classification probabilities.\n","        \"\"\"\n","        out = self.transformer(input_ids=input_ids, attention_mask=attention_mask, training=training)\n","        return tf.nn.softmax(out.logits, axis=-1)\n","    \n","    def get_config(self):\n","        return {}\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        return cls(**config)"],"metadata":{"id":"PMnX3oeq9cLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auto_model = AutoModelWrapper(model)\n"],"metadata":{"id":"df4-coRj9cwK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(auto_model)"],"metadata":{"id":"nRE61PqSuD5T","executionInfo":{"status":"ok","timestamp":1654698572569,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"2237ea9f-eb9a-4d54-de8f-2f36b8b5bd8c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.AutoModelWrapper object at 0x7fd184ec36d0>\n"]}]},{"cell_type":"code","source":["max_features = 10000\n","max_len = 128"],"metadata":{"id":"AfH8Kc4D9tKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_samples = ['I love you, I like you', \n","                'I love you, I like you, but I also kind of dislike you',\n","                'Everything is so nice about you']\n","\n","# since using the uncased model, we need to use lowercase sentences\n","text_samples = [text.lower() for text in text_samples]\n","\n","# tokenize the sentences using the transformer's tokenizer.\n","tokenized_samples = process_sentences(text_samples, tokenizer, max_len)\n","X_test = tokenized_samples['input_ids'].astype(np.int32)\n","\n","# the values of the kwargs have to be `tf.Tensor`. \n","# see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n","kwargs = {k: tf.constant(v) for k,v in tokenized_samples.items() if k == 'attention_mask'}"],"metadata":{"id":"O6wuUW559z-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auto_model.layers[0].layers"],"metadata":{"id":"hb9I14xU91AV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654341371081,"user_tz":-120,"elapsed":304,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"42628a2a-34a3-4d22-b5d0-2d029c9680b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f256fec0ed0>,\n"," <keras.layers.core.dropout.Dropout at 0x7f25981916d0>,\n"," <keras.layers.core.dense.Dense at 0x7f2598099bd0>]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["layer = auto_model.layers[0].layers[0].embeddings"],"metadata":{"id":"x8zORSs193AJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_steps = 50\n","internal_batch_size = 5\n","method = \"gausslegendre\"\n","\n","ig  = IntegratedGradients(auto_model,\n","                          layer=layer,\n","                          n_steps=n_steps, \n","                          method=method,\n","                          internal_batch_size=internal_batch_size)"],"metadata":{"id":"9NdoQzin96W6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = auto_model(X_test, **kwargs).numpy().argmax(axis=1)\n","\n","# Get the baselines. Note that the baseline contains special characters (e.g, [CLS], [SEP], [UNK] [PAD]) and\n","# the regular tokens are replaced by the [PAD] token which is a neutral token.\n","# By including special tokens such as [CLS], [SEP], [UNK], we ensure that the attribution for those tokens\n","# will be 0 if we use the embedding layer. The 0 attribution is due to integration between [x, x] which is 0.\n","mask = np.isin(X_test, tokenizer.all_special_ids)\n","baselines = X_test * mask + tokenizer.pad_token_id * (1 - mask)\n","\n","# get explanation\n","explanation = ig.explain(X_test, \n","                         forward_kwargs=kwargs,\n","                         baselines=baselines, \n","                         target=predictions)"],"metadata":{"id":"B-cmn87X97GX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attrs = explanation.attributions[0]\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z41yp2AP9-_t","executionInfo":{"status":"ok","timestamp":1654341419449,"user_tz":-120,"elapsed":312,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"2d3287de-a0f3-4760-b886-49e06393718a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (3, 128, 768)\n"]}]},{"cell_type":"code","source":["attrs = attrs.sum(axis=2)\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmXYJlOZ9_oY","executionInfo":{"status":"ok","timestamp":1654341421134,"user_tz":-120,"elapsed":290,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"0b216415-dcee-47f1-ae98-69d4af7b9c0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (3, 128)\n"]}]},{"cell_type":"code","source":["index = 0\n","display(X=X_test[index], attrs=attrs[index], pred=predictions[index], tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"cYyhiaeP-BoF","executionInfo":{"status":"ok","timestamp":1654341422792,"user_tz":-120,"elapsed":288,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"c9a596ff-a039-47ce-85f8-1c61a0c78852"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted label =  0: Negative review\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<mark style=background-color:#f7f7f6>[CLS] </mark><mark style=background-color:#f9eef4>i </mark><mark style=background-color:#c2197a>love </mark><mark style=background-color:#306f1b>you </mark><mark style=background-color:#f6f7f5>, </mark><mark style=background-color:#276419>i </mark><mark style=background-color:#d24c97>like </mark><mark style=background-color:#f9f1f5>you </mark><mark style=background-color:#f7f7f6>[SEP] </mark>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"xgWY4Blirp19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_csv(\"FINBERT-allData (1).csv\", encoding=\"latin\", header=[0])\n","text=df['Description']\n","label=df['Semantic']"],"metadata":{"id":"MzlEaJ64rrb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s=text.head(20)\n","print(s[3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2O63wzTrvwf","executionInfo":{"status":"ok","timestamp":1654341438046,"user_tz":-120,"elapsed":4,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"78b85812-dbca-4dd8-cd90-26240fb7910c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .\n"]}]},{"cell_type":"code","source":["s = [text.lower() for text in s]\n","\n","# tokenize the sentences using the transformer's tokenizer.\n","tokenized_samples = process_sentences(s, tokenizer, max_len)\n","X_test = tokenized_samples['input_ids'].astype(np.int32)\n","\n","# the values of the kwargs have to be `tf.Tensor`. \n","# see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n","kwargs = {k: tf.constant(v) for k,v in tokenized_samples.items() if k == 'attention_mask'}"],"metadata":{"id":"brpZUOhzsrx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(s)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMvenz_ksv_9","executionInfo":{"status":"ok","timestamp":1654341441928,"user_tz":-120,"elapsed":288,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"250507bb-b86d-4af0-df66-d25d0d5b2b27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['according to gran , the company has no plans to move all production to russia , although that is where the company is growing .', 'technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .', 'the international electronic industry company elcoteq has laid off tens of employees from its tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily postimees reported .', 'with the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .', \"according to the company 's updated strategy for the years 2009-2012 , basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .\", \"financing of aspocomp 's growth aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding hdi printed circuit boards pcbs .\", \"for the last quarter of 2010 , componenta 's net sales doubled to eur131m from eur76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of eur7m .\", 'in the third quarter of 2010 , net sales increased by 5.2 % to eur 205.5 mn , and operating profit by 34.9 % to eur 23.5 mn .', 'operating profit rose to eur 13.1 mn from eur 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .', 'operating profit totalled eur 21.1 mn , up from eur 18.6 mn in 2007 , representing 9.7 % of net sales .', \"teliasonera tlsn said the offer is in line with its strategy to increase its ownership in core business holdings and would strengthen eesti telekom 's offering to its customers .\", 'stora enso , norske skog , m-real , upm-kymmene credit suisse first boston ( cfsb ) raised the fair value for shares in four of the largest nordic forestry groups .', 'a purchase agreement for 7,200 tons of gasoline with delivery at the hamina terminal , finland , was signed with neste oil oyj at the average platts index for this september plus eight us dollars per month .', 'finnish talentum reports its operating profit increased to eur 20.5 mn in 2005 from eur 9.3 mn in 2004 , and net sales totaled eur 103.3 mn , up from eur 96.4 mn .', \"clothing retail chain sepp+l+ 's sales increased by 8 % to eur 155.2 mn , and operating profit rose to eur 31.1 mn from eur 17.1 mn in 2004 .\", 'consolidated net sales increased 16 % to reach eur74 .8 m , while operating profit amounted to eur0 .9 m compared to a loss of eur0 .7 m in the prior year period .', 'foundries division reports its sales increased by 9.7 % to eur 63.1 mn from eur 57.5 mn in the corresponding period in 2006 , and sales of the machine shop division increased by 16.4 % to eur 41.2 mn from eur 35.4 mn in the corresponding period in 2006 .', \"helsinki ( afx ) - shares closed higher , led by nokia after it announced plans to team up with sanyo to manufacture 3g handsets , and by nokian tyres after its fourth-quarter earnings report beat analysts ' expectations , dealers said .\", 'incap contract manufacturing services pvt ltd , a subsidiary of incap corporation of finland , plans to double its revenues by 2007-2008 .', 'its board of directors will propose a dividend of eur0 .12 per share for 2010 , up from the eur0 .08 per share paid in 2009 .']\n"]}]},{"cell_type":"code","source":["auto_model.layers[0].layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-xcQSTPs_jv","executionInfo":{"status":"ok","timestamp":1654341443849,"user_tz":-120,"elapsed":271,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"2fc13bea-4c76-4f68-965e-7b54282b1ca7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f256fec0ed0>,\n"," <keras.layers.core.dropout.Dropout at 0x7f25981916d0>,\n"," <keras.layers.core.dense.Dense at 0x7f2598099bd0>]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["layer = auto_model.layers[0].layers[0].embeddings"],"metadata":{"id":"WwPHaGAqtGmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_steps = 50\n","internal_batch_size = 5\n","method = \"gausslegendre\"\n","\n","ig  = IntegratedGradients(auto_model,\n","                          layer=layer,\n","                          n_steps=n_steps, \n","                          method=method,\n","                          internal_batch_size=internal_batch_size)"],"metadata":{"id":"3efR69HBtKX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = auto_model(X_test, **kwargs).numpy().argmax(axis=1)\n","\n","# Get the baselines. Note that the baseline contains special characters (e.g, [CLS], [SEP], [UNK] [PAD]) and\n","# the regular tokens are replaced by the [PAD] token which is a neutral token.\n","# By including special tokens such as [CLS], [SEP], [UNK], we ensure that the attribution for those tokens\n","# will be 0 if we use the embedding layer. The 0 attribution is due to integration between [x, x] which is 0.\n","mask = np.isin(X_test, tokenizer.all_special_ids)\n","baselines = X_test * mask + tokenizer.pad_token_id * (1 - mask)\n","\n","# get explanation\n","explanation = ig.explain(X_test, \n","                         forward_kwargs=kwargs,\n","                         baselines=baselines, \n","                         target=predictions)"],"metadata":{"id":"hy7eie2ztKgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attrs = explanation.attributions[0]\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wICagTqPtKjK","executionInfo":{"status":"ok","timestamp":1654341508346,"user_tz":-120,"elapsed":280,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"6b64f0aa-7e21-41c6-e6e1-fca49ef8fed3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (20, 128, 768)\n"]}]},{"cell_type":"code","source":["attrs = attrs.sum(axis=2)\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5cmAeeJtKl9","executionInfo":{"status":"ok","timestamp":1654341509555,"user_tz":-120,"elapsed":1,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"13f353c5-fa7b-4af1-8d8c-d1cb892cb033"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (20, 128)\n"]}]},{"cell_type":"code","source":["index = 3\n","display(X=X_test[index], attrs=attrs[index], pred=predictions[index], tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"UdvHtXlNtKog","executionInfo":{"status":"ok","timestamp":1654341511686,"user_tz":-120,"elapsed":414,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"62041b20-b90b-4220-87b1-05a833677e6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted label =  1: Positive review\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<mark style=background-color:#f7f7f6>[CLS] </mark><mark style=background-color:#fde0ef>with </mark><mark style=background-color:#f7f6f7>the </mark><mark style=background-color:#f2b8db>new </mark><mark style=background-color:#f9d1e8>production </mark><mark style=background-color:#f1f6e8>plant </mark><mark style=background-color:#fbe8f2>the </mark><mark style=background-color:#f8f4f6>company </mark><mark style=background-color:#8e0152>would </mark><mark style=background-color:#900254>increase </mark><mark style=background-color:#fce5f1>its </mark><mark style=background-color:#f9eff4>capacity </mark><mark style=background-color:#d65a9f>to </mark><mark style=background-color:#fbd8eb>meet </mark><mark style=background-color:#de77ae>the </mark><mark style=background-color:#a1d26a>expected </mark><mark style=background-color:#dff2c4>increase </mark><mark style=background-color:#fce5f1>in </mark><mark style=background-color:#edf6e1>demand </mark><mark style=background-color:#f8f2f5>and </mark><mark style=background-color:#f2badc>would </mark><mark style=background-color:#f1f6ea>improve </mark><mark style=background-color:#f5f7f3>the </mark><mark style=background-color:#f9f1f5>use </mark><mark style=background-color:#fce4f0>of </mark><mark style=background-color:#f7f7f7>raw </mark><mark style=background-color:#f9f0f5>materials </mark><mark style=background-color:#f4bfdf>and </mark><mark style=background-color:#b9e187>therefore </mark><mark style=background-color:#c82884>increase </mark><mark style=background-color:#fad6ea>the </mark><mark style=background-color:#f7f6f7>production </mark><mark style=background-color:#f5f7f3>profit </mark><mark style=background-color:#d8efb9>##ability </mark><mark style=background-color:#eaf5d9>. </mark><mark style=background-color:#f7f7f6>[SEP] </mark>"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# print(s[3])\n","s[3]=s[3].replace(\"increase\", \"adjust\")\n","print(s[3])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvzVImozde7d","executionInfo":{"status":"ok","timestamp":1654341515733,"user_tz":-120,"elapsed":313,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"45904b00-7f4e-47dd-c1d3-d90657344a8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["with the new production plant the company would adjust its capacity to meet the expected adjust in demand and would improve the use of raw materials and therefore adjust the production profitability .\n"]}]},{"cell_type":"code","source":["text[3]=s[3]\n","print(text[3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"siXXSvylXhdj","executionInfo":{"status":"ok","timestamp":1654341517392,"user_tz":-120,"elapsed":335,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"f65937f2-bb70-4a22-b924-ea48d1af1b0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["with the new production plant the company would adjust its capacity to meet the expected adjust in demand and would improve the use of raw materials and therefore adjust the production profitability .\n"]}]},{"cell_type":"code","source":["s = [text.lower() for text in s]\n","\n","# tokenize the sentences using the transformer's tokenizer.\n","tokenized_samples = process_sentences(s, tokenizer, max_len)\n","X_test = tokenized_samples['input_ids'].astype(np.int32)\n","\n","# the values of the kwargs have to be `tf.Tensor`. \n","# see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n","kwargs = {k: tf.constant(v) for k,v in tokenized_samples.items() if k == 'attention_mask'}"],"metadata":{"id":"1GODgU30YCIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auto_model.layers[0].layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E50Gs5k-YJ5n","executionInfo":{"status":"ok","timestamp":1654341520318,"user_tz":-120,"elapsed":3,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"734be3a7-6e22-42a3-99b7-cfefffea535c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f256fec0ed0>,\n"," <keras.layers.core.dropout.Dropout at 0x7f25981916d0>,\n"," <keras.layers.core.dense.Dense at 0x7f2598099bd0>]"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["layer = auto_model.layers[0].layers[0].embeddings"],"metadata":{"id":"huR4GAgeYTH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_steps = 50\n","internal_batch_size = 5\n","method = \"gausslegendre\"\n","\n","ig  = IntegratedGradients(auto_model,\n","                          layer=layer,\n","                          n_steps=n_steps, \n","                          method=method,\n","                          internal_batch_size=internal_batch_size)"],"metadata":{"id":"HZe-lOVKYW35"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = auto_model(X_test, **kwargs).numpy().argmax(axis=1)\n","\n","# Get the baselines. Note that the baseline contains special characters (e.g, [CLS], [SEP], [UNK] [PAD]) and\n","# the regular tokens are replaced by the [PAD] token which is a neutral token.\n","# By including special tokens such as [CLS], [SEP], [UNK], we ensure that the attribution for those tokens\n","# will be 0 if we use the embedding layer. The 0 attribution is due to integration between [x, x] which is 0.\n","mask = np.isin(X_test, tokenizer.all_special_ids)\n","baselines = X_test * mask + tokenizer.pad_token_id * (1 - mask)\n","\n","# get explanation\n","explanation = ig.explain(X_test, \n","                         forward_kwargs=kwargs,\n","                         baselines=baselines, \n","                         target=predictions)"],"metadata":{"id":"lHPF3CDeYaaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attrs = explanation.attributions[0]\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-ZMSc2wYrhr","executionInfo":{"status":"ok","timestamp":1654341579706,"user_tz":-120,"elapsed":21,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"a3ef4b0f-b384-45fa-fb84-111c965233a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (20, 128, 768)\n"]}]},{"cell_type":"code","source":["attrs = attrs.sum(axis=2)\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLExSg-FYvuZ","executionInfo":{"status":"ok","timestamp":1654341579706,"user_tz":-120,"elapsed":10,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"9ddbec82-3927-4b3d-9bc0-96a06346de40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (20, 128)\n"]}]},{"cell_type":"code","source":["index = 3\n","display(X=X_test[index], attrs=attrs[index], pred=predictions[index], tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"oPzVZfELY1rU","executionInfo":{"status":"ok","timestamp":1654341579706,"user_tz":-120,"elapsed":8,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"138a1164-75d6-4c8e-ed7c-10098ba938bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted label =  0: Negative review\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<mark style=background-color:#f7f7f6>[CLS] </mark><mark style=background-color:#ebf6dc>with </mark><mark style=background-color:#bde38d>the </mark><mark style=background-color:#d4edb3>new </mark><mark style=background-color:#f1b7da>production </mark><mark style=background-color:#b9e187>plant </mark><mark style=background-color:#eef6e2>the </mark><mark style=background-color:#a9d874>company </mark><mark style=background-color:#98cc5f>would </mark><mark style=background-color:#f4f7f0>adjust </mark><mark style=background-color:#67a832>its </mark><mark style=background-color:#e9f5d8>capacity </mark><mark style=background-color:#d4edb3>to </mark><mark style=background-color:#faedf3>meet </mark><mark style=background-color:#77b53c>the </mark><mark style=background-color:#f5c2e0>expected </mark><mark style=background-color:#f5f7f3>adjust </mark><mark style=background-color:#e7f5d2>in </mark><mark style=background-color:#f7f7f7>demand </mark><mark style=background-color:#f0f6e7>and </mark><mark style=background-color:#eeabd2>would </mark><mark style=background-color:#276419>improve </mark><mark style=background-color:#a9d874>the </mark><mark style=background-color:#c4e699>use </mark><mark style=background-color:#b7e085>of </mark><mark style=background-color:#f5f7f2>raw </mark><mark style=background-color:#e6f5d0>materials </mark><mark style=background-color:#c2e596>and </mark><mark style=background-color:#efb0d6>therefore </mark><mark style=background-color:#e2f3ca>adjust </mark><mark style=background-color:#64a52f>the </mark><mark style=background-color:#faecf3>production </mark><mark style=background-color:#ae106b>profit </mark><mark style=background-color:#f8cee6>##ability </mark><mark style=background-color:#f7cce5>. </mark><mark style=background-color:#f7f7f6>[SEP] </mark>"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# print(s[3])\n","s[3]=s[3].replace(\"adjust\", \"decrease\")\n","print(s[3])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6OU_AMhegor","executionInfo":{"status":"ok","timestamp":1654341864257,"user_tz":-120,"elapsed":403,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"25efd1a9-67b9-49a0-84ab-096ba9a33f61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["with the new production plant the company would decrease its capacity to meet the expected decrease in demand and would improve the use of raw materials and therefore decrease the production profitability .\n"]}]},{"cell_type":"code","source":["text[3]=s[3]\n","print(text[3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJKspxOjegrv","executionInfo":{"status":"ok","timestamp":1654341866938,"user_tz":-120,"elapsed":415,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"52447432-5d3f-4f5e-f475-00bdc54bc812"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["with the new production plant the company would decrease its capacity to meet the expected decrease in demand and would improve the use of raw materials and therefore decrease the production profitability .\n"]}]},{"cell_type":"code","source":["s = [text.lower() for text in s]\n","\n","# tokenize the sentences using the transformer's tokenizer.\n","tokenized_samples = process_sentences(s, tokenizer, max_len)\n","X_test = tokenized_samples['input_ids'].astype(np.int32)\n","\n","# the values of the kwargs have to be `tf.Tensor`. \n","# see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n","kwargs = {k: tf.constant(v) for k,v in tokenized_samples.items() if k == 'attention_mask'}"],"metadata":{"id":"IyRD0Yvuegu_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auto_model.layers[0].layers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JH_BO0jVegxd","executionInfo":{"status":"ok","timestamp":1654341871723,"user_tz":-120,"elapsed":272,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"c77936a8-e96b-48f5-eb7c-9ffc49174d25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<transformers.models.bert.modeling_tf_bert.TFBertMainLayer at 0x7f256fec0ed0>,\n"," <keras.layers.core.dropout.Dropout at 0x7f25981916d0>,\n"," <keras.layers.core.dense.Dense at 0x7f2598099bd0>]"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["layer = auto_model.layers[0].layers[0].embeddings"],"metadata":{"id":"HnZsk5cmeg0l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_steps = 50\n","internal_batch_size = 5\n","method = \"gausslegendre\"\n","\n","ig  = IntegratedGradients(auto_model,\n","                          layer=layer,\n","                          n_steps=n_steps, \n","                          method=method,\n","                          internal_batch_size=internal_batch_size)"],"metadata":{"id":"P_V_X_jJeg6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = auto_model(X_test, **kwargs).numpy().argmax(axis=1)\n","\n","# Get the baselines. Note that the baseline contains special characters (e.g, [CLS], [SEP], [UNK] [PAD]) and\n","# the regular tokens are replaced by the [PAD] token which is a neutral token.\n","# By including special tokens such as [CLS], [SEP], [UNK], we ensure that the attribution for those tokens\n","# will be 0 if we use the embedding layer. The 0 attribution is due to integration between [x, x] which is 0.\n","mask = np.isin(X_test, tokenizer.all_special_ids)\n","baselines = X_test * mask + tokenizer.pad_token_id * (1 - mask)\n","\n","# get explanation\n","explanation = ig.explain(X_test, \n","                         forward_kwargs=kwargs,\n","                         baselines=baselines, \n","                         target=predictions)"],"metadata":{"id":"HLCsV9-mgQ7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attrs = explanation.attributions[0]\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0OrkoSmBgQ-j","executionInfo":{"status":"ok","timestamp":1654341952433,"user_tz":-120,"elapsed":352,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"63d05316-aef3-4d04-8b14-416f7423c23d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (20, 128, 768)\n"]}]},{"cell_type":"code","source":["attrs = attrs.sum(axis=2)\n","print('Attributions shape:', attrs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKCSqiDKgRBU","executionInfo":{"status":"ok","timestamp":1654341954244,"user_tz":-120,"elapsed":313,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"47eff774-9dc3-4bb2-9e6e-fe3bf8f005e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attributions shape: (20, 128)\n"]}]},{"cell_type":"code","source":["index = 3\n","display(X=X_test[index], attrs=attrs[index], pred=predictions[index], tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"6eJOP6QmgREw","executionInfo":{"status":"error","timestamp":1654341973499,"user_tz":-120,"elapsed":288,"user":{"displayName":"Fatjon Huseini","userId":"04797314500465995857"}},"outputId":"b2b830c0-3f52-4eb6-dfe2-a65f287e2bf8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-903acf4c761d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-e581513a7782>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(X, attrs, tokenizer, pred)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted label =  {}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhlstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 2"]}]}]}